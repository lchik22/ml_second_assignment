# IEEE-CIS Fraud Detection

კონკურსში, მოცემული გვქონდა დიდი მონაცემთა სიმრავლე, რომლის დასწავლითაც ჩვენს მოდელს უნდა გამოეცნო პარავდნენ თუ არა გერმანელ ბებოებს ფულს. მოდელი ფასდება roc-auc მეტრიკით.

---

# რეპოზიტორიის სტრუქტურა

- `models/` — ამ ფოლდერში, არის ძირითადი მოდელების ტრენინგ კოდები და ზოგადი მონაცემთა ანალიზის notebook.
- `model-inference.ipynb` - submission ფაილის შექმნის კოდი

---

# Feature Engineering

## Nan მნიშვნელობების დამუშავება

პირველ რიგში გადავაგდე, ყველა feature, რომელშიც 90%-ზე მეტი NaN იყო. ეს ისევე, როგორც ბევრი სხვა პარამეტრი, ავარჩიე მონაცემებზე დაკვირვებით.

Nan მნიშვნელობის დამუშავებისას, ყველა მოდელისთვის საერთო მეთოდი გამოვიყენე. numerical feature-ები შევავსე მედიანით, ხოლო categorical feature-ები კონსტანტათი.

## კატეგორიული ცვლადების რიცხვითში გადაყვანა

ძირითადი, მიდგომა იყო one-hot encoding + woe, ანუ თუ განსხვავებული მონაცემების რაოდენობა 3-ზე დიდი იყო რომელიმე feature-ში, მაშინ მასზე woe-ს გამოვიყენებდი, თუ არა და one-hot-ს. ეს threshold ლოგიკური მომეჩვენა, რადგან მონაცემები ისედაც დიდი იყო, და One Hot Encoding-ის საშუალებით მისი გაზრდა შემდგომ პროცესებს გააუარესებდა.

# Feature Selection

## გამოყენებული მიდგომები

პირველი, რაც ყველა მოდელზე ვცადე იყო RFE, თუმცა მისი გამოყენება დიდი პარამეტრებით LogisticRegression მოდელზე არ მიცდია, რადგან დროს დავკარგავდი. XGboost-ზე მშვენივრად იმუშავა. 

## შეფასება

მოდელის შესაფასებლად უბრალოდ, გავყავი სიმრავლე ორ ნაწილად X_train, y_train და X_valid, y_valid. მოდელის საბოლოო ქულა დამოკიდებული იყო მის შედეგზე X_valid, y_valid სიმრავლეებზე, კერძოდ roc_auc ქულაზე.

# Training

## ტესტირებული მოდელები

- Logistic Regression
- XGBoost Classifier


## Logistic Regresion

გამოვიყენე ზემოთ ნახსენები, feature-engineering ტექნიკები (სხვადასხვა პარამეტრებით). გამოვიყენე saga solver. როგორც დაკვირვებამ მაჩვენა მოდელის ტრენინგისას, Logistic Regresion ძალიან ცუდი მოდელია ამ კონკურსისთვის, ვინაიდან ტრენინგს დიდი დრო დასჭირდა, ხოლო roc_auc შედეგი საკმაოდ დაბალი ქონდა, როგორც ტრენინგ დატაზე, ასევე ვალიდაციისაზე.

Logistic Regresion არ არის საკმარისად კომპლექსური მოდელი მონაცემების აღსაწერად, რაც განაპირობებს ზემოთ აღწერილ შედეგებს.


## XGboost

თავდაპირველად გამოვიყენე იგივე Feature Engineering/Selection მეთოდები, რაც წინა მოდელებში.
ამ მოდელს შედარებით მაღალი ვარიაცია აქვს. შესაძლოა ჰქონდეს overfitting-ის პრობლემაც, ამიტომ ამისგან თავდასაცავად გადავარჩიე რეგულაციის პარამეტრები.

ქროს ვალიდაციით შევარჩიე მოდელის ჰიპერპარამეტრები და მივიღე შემდეგი მოდელი:

- **max_depth** = 25
- **min_child_weight** = 1
- **reg_alpha** = 0
- **reg_lambda** = 10
- **corelation_threashold** = 0.9
- **remained_features** - (იხილეთ MLFlow-ზე)
- **roc_auc_train** = 1
- **roc_auc_valid** = .97

## საბოლოო მოდელის შერჩევა

პროდაქშენ მოდელად ავარჩიე xgboost საუკეთესო შედეგის გამო.

---

# MLflow Tracking

## MLflow ექსპერიმენტის ბმული

[MLflow Experiment](https://dagshub.com/lchik22/ml_second_assignment.mlflow/)

## ჩაწერილი მეტრიკები

ROC-AUC

## საუკეთესო მოდელის შედეგები

- **Validation ROC AUC**:  0.9665381633852301
- **Test ROC AUC**: 0.902716/0.866426